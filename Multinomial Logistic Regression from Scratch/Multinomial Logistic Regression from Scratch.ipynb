{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from numpy import genfromtxt\n",
    "import csv\n",
    "import string\n",
    "import re\n",
    "from numpy import errstate,isneginf,array\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression\n",
    "### For Tweets Multiclass Sentiment Analysis (Positive, Negitive, Neutral)\n",
    "### Implementation of Cost Function, Gradient descent and Stochastic gradient for multivariate linear regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "noOfClass = 3  # three classes\n",
    "dataset_dir = r'Tweets.csv' #directory\n",
    "stopWords = ['the','at','of', 'this','hence','an','do' , 'us', 'r' , 'u', 'ill','aa', 'did', 'im','also','with', 'to' ,'he','she', 'or' , 'a','that', 'in' , 'is' ,'on', 'for', 'our', 'by' , 'its' , 'my', 'your', 'you' , 'me', 'i', 'it', 'are', 'am','into', 'were' , 'was' , 'and' , 'so' , 'has', 'have', 'been','had', 'be' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,W):\n",
    "    hx=np.dot(X,W)\n",
    "    return hx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace each label with numeric value\n",
    "def labelCovert(label):\n",
    "    if label  == 'neutral': return 0       \n",
    "    elif label  == 'positive': return 1\n",
    "    elif  label  == 'negative': return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove puncutaiton from each tweet\n",
    "def remove_punctuation(sentence):\n",
    "    return sentence.translate(str.maketrans('', '', string.punctuation))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return array of bag of words \n",
    "def bagOfWords(text, vocab):\n",
    "    #sentence_words = extract_words(sentence)\n",
    "    # frequency word count\n",
    "    bag = np.zeros(len(vocab))\n",
    "    for word in text:\n",
    "        for i,w in enumerate(vocab):    #prepare bag of words\n",
    "            if w == word: \n",
    "                bag[i] += 1\n",
    "                \n",
    "    return np.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and seperate text and their labels\n",
    "labels = []\n",
    "texts = []\n",
    "with open(dataset_dir,'r',  encoding='utf8') as file:     \n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        labels.append(row[0])\n",
    "        texts.append(row[1])\n",
    "labels = labels[1:]\n",
    "texts = texts[0:]\n",
    "\n",
    "labels = [labelCovert(label) for label in labels ]\n",
    "labels, texts = zip(*sorted(zip(labels, texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    " #splits data into train and test in stratified way\n",
    "def splitData(labels, texts , splitPercentage):  \n",
    "    trainLabels =[]\n",
    "    testLabels = []\n",
    "    \n",
    "    trainTexts = []\n",
    "    testTexts = []\n",
    "    \n",
    "    neutralCount = labels.count(0)\n",
    "    positiveCount = labels.count(1)\n",
    "    negativeCount = labels.count(2)\n",
    "    \n",
    "    testNeutralCount = int(neutralCount * splitPercentage)\n",
    "    testPositiveCount = int(positiveCount * splitPercentage)\n",
    "    testNegativeCount = int(negativeCount * splitPercentage)\n",
    "\n",
    "    \n",
    "    testLabels = testLabels + list(labels[: (testNeutralCount)])\n",
    "    testTexts = testTexts + list(texts[: (testNeutralCount)])\n",
    "    \n",
    "    trainLabels = trainLabels + list(labels[testNeutralCount : (neutralCount )])\n",
    "    trainTexts = trainTexts +  list(texts[testNeutralCount : (neutralCount)])\n",
    "    \n",
    "    testPositiveCount =  neutralCount + testPositiveCount         \n",
    "\n",
    "    \n",
    "    testLabels = testLabels + list(labels[neutralCount : testPositiveCount])\n",
    "    testTexts = testTexts + list(texts[ neutralCount : testPositiveCount])\n",
    "    \n",
    "    trainLabels = trainLabels + list(labels[testPositiveCount : (neutralCount+positiveCount)])\n",
    "    trainTexts = trainTexts + list(texts[testPositiveCount : (neutralCount+positiveCount)])\n",
    "    \n",
    "    testNegativeCount =  neutralCount + positiveCount + testNegativeCount\n",
    "    \n",
    "    testLabels = testLabels + list(labels[(neutralCount+positiveCount) : testNegativeCount])\n",
    "    testTexts = testTexts + list(texts[ (neutralCount+positiveCount ) : testNegativeCount])\n",
    "    \n",
    "    trainLabels = trainLabels + list(labels[testNegativeCount:])\n",
    "    trainTexts = trainTexts + list(texts[testNegativeCount: ])\n",
    "    \n",
    "    return testLabels, testTexts ,trainLabels , trainTexts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testLabels, testTexts ,trainLabels , trainTexts =  splitData(labels, texts , 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleans data by removing punctuations, stop words etc\n",
    "def cleanData(texts):\n",
    "    \n",
    "    for i,_ in enumerate(texts):\n",
    "        texts[i] = ' '.join(word for word in texts[i].split(' ') if not word.startswith('@')) #remove airline name\n",
    "        \n",
    "    texts = [str(np.char.lower(text)) for text in texts]  #lower case\n",
    "    texts = [remove_punctuation(text) for text in texts]  # remove puncuation\n",
    "    \n",
    "    for i,_ in enumerate(texts):\n",
    "        texts[i] = ' '.join(word for word in texts[i].split() if word not in stopWords) #remove stop words\n",
    "        texts[i] = re.sub(r\"http\\S+\", \"\", texts[i])  #remove URL\n",
    "        \n",
    "    return texts\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for bag of words\n",
    "def preProcessTextData(trainTexts, testTest):\n",
    "    trainTexts = cleanData(trainTexts)  # clean train tweets\n",
    "    testTest = cleanData(testTest)  # clean test tweets\n",
    "    \n",
    "    tokenizeTrainText = [text.split() for text in trainTexts] # tokenize train tweets\n",
    "    tokenizeTestText = [text.split() for text in testTest] # tokenize train tweets\n",
    "    \n",
    "    vocab = []\n",
    "    \n",
    "    for text in tokenizeTrainText:\n",
    "        vocab = vocab + text   # preparing list of all the words in train data\n",
    "    \n",
    "    for text in tokenizeTestText:\n",
    "        vocab = vocab + text   # preparing list of all the words test data\n",
    "        \n",
    "    vocab = set(vocab)  #remove dupliacates to prepare vocabloury of dataset\n",
    "    \n",
    "    trainDataList = [bagOfWords(text,vocab) for text in  tokenizeTrainText]   #bag of words for train data\n",
    "    trainDataMatrix = np.vstack(trainDataList)    # data Matrix for train data\n",
    "    trainBais = np.ones(trainDataMatrix.shape[0])\n",
    "    trainDataMatrix = np.column_stack((trainBais, trainDataMatrix))  # adding column for bais\n",
    "    \n",
    "    \n",
    "    testDataList = [bagOfWords(text,vocab) for text in  tokenizeTestText]   #bag of words for test data\n",
    "    testDataMatrix = np.vstack(testDataList)  # data Matrix for train data\n",
    "    testBais = np.ones(testDataMatrix.shape[0])\n",
    "    testDataMatrix = np.column_stack((testBais,testDataMatrix))  # adding column for bais\n",
    "    \n",
    "    \n",
    "    return vocab, trainDataMatrix , testDataMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, trainDataMatrix , testDataMatrix  = preProcessTextData(trainTexts ,testTexts )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change label into 3 digits\n",
    "def preProcessLabelData(trainLabels, testLabels):    \n",
    "    \n",
    "    newTrainLabels = np.zeros((len(trainLabels), noOfClass))\n",
    "    \n",
    "    for i in range(newTrainLabels.shape[0]):\n",
    "        newTrainLabels[i,trainLabels[i]] = 1\n",
    "\n",
    "    \n",
    "    newTextLabels = np.zeros((len(testLabels), noOfClass))\n",
    "    \n",
    "    for i in range(newTextLabels.shape[0]):\n",
    "        newTextLabels[i,testLabels[i]] = 1\n",
    "        \n",
    "    return newTrainLabels, newTextLabels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTrainLabels, newTextLabels =  preProcessLabelData(trainLabels, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns intial weights to start with\n",
    "def predictInitialWeight(DataMatrix):\n",
    "    weightMatrix = np.zeros(( noOfClass, DataMatrix.shape[1]))     #initial random weights\n",
    "    weightMatrix.fill(0.0)\n",
    "    return weightMatrix.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialWeightMatrix =  predictInitialWeight(trainDataMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ P(y=c|x) = \\frac{e^{w_c.x+b_c}}{\\sum_{j=1}^{k}e^{w_j.x+b_j}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax \n",
    "def getProbablities(dataMatrix, weights):\n",
    "    \n",
    "    probablities = predict(dataMatrix,weights)\n",
    "    probablities = np.exp(probablities)\n",
    "    sumHX = probablities.sum(axis=1)\n",
    "\n",
    "    for i in range(len(sumHX)):\n",
    "        probablities[i,:] =  probablities[i,:]/ sumHX[i]\n",
    "        \n",
    "    return probablities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialProbablities = getProbablities(trainDataMatrix,initialWeightMatrix )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L_{CE} (\\hat{y},y) =  - \\sum_{k=1}^{K}1 \\{y=k\\}log \\frac{e^{w_c.x+b_c}}{\\sum_{j=1}^{k}e^{w_j.x+b_j}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate loss\n",
    "def lossFunction(dataMatrix, weightMatrix, trainLabels):\n",
    "    \n",
    "    probablities = getProbablities(dataMatrix, weightMatrix)   #return probablities\n",
    "    \n",
    "    logProbablities = np.log(probablities)      #log of probabilities\n",
    "    multiplication =  trainLabels * logProbablities    #multiply log of probablity with output labels\n",
    "    summation = multiplication.sum(axis=1)             # sum all the 3 output variables of each row\n",
    "    summation = np.sum(summation)                      #sum all the variables in summation \n",
    "            \n",
    "    totalLoss = -(summation/trainLabels.shape[0])       # divide by number of rows\n",
    "    \n",
    "    return totalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = lossFunction(trainDataMatrix, initialWeightMatrix, newTrainLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0986122886681096"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrurn Slective row of data and train labels for batch stochatic gradient \n",
    "def getSelectedMatrices(rowNumbers, dataMatrix, trainLabels ):\n",
    "    \n",
    "    selectedDataMatrix = np.zeros((len(rowNumbers),dataMatrix.shape[1]), dtype = float)\n",
    "    selectedTrainLabels = np.zeros((len(rowNumbers),trainLabels.shape[1]), dtype = float)\n",
    "    \n",
    "    for index,rowNo in enumerate(rowNumbers):\n",
    "        selectedDataMatrix[index,:] = dataMatrix[rowNo,:]\n",
    "        selectedTrainLabels[index,:] = trainLabels[rowNo,:]\n",
    "        \n",
    "    return selectedDataMatrix, selectedTrainLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\theta_j = \\theta_j - \\frac{\\alpha}{m} (-(1\\{y=k\\}\\frac{e^{w_c.x+b_c}}{\\sum_{j=1}^{k}e^{w_j.x+b_j}})x_k)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient stochastic\n",
    "def gradientscrochastic(dataMatrix, weightMatrix, trainLabels , alpha ,  epochs):\n",
    "    \n",
    "    \n",
    "    cost = []\n",
    "    \n",
    "    for epoch in range(epochs):   #no of epochs\n",
    "\n",
    "        rowNumbers = random.sample(range(1, (dataMatrix.shape[0] - 1)), 32)  #select 32 random indices for minibatch\n",
    "        m = len(rowNumbers)\n",
    "        stochasticDataMatrix , stochasticTrainLabels = getSelectedMatrices(rowNumbers,dataMatrix, trainLabels)\n",
    "        \n",
    "        probabilities = getProbablities(stochasticDataMatrix, weightMatrix)\n",
    "        \n",
    "        loss = stochasticTrainLabels - probabilities\n",
    "        \n",
    "        for feature in range(dataMatrix.shape[1]):    #for no of features\n",
    "        \n",
    "            featureData = stochasticDataMatrix[:,feature].reshape(-1,1)\n",
    "            multi = np.multiply(loss, featureData)\n",
    "            multi = multi * -1\n",
    "            summation = multi.sum(axis=0)\n",
    "            weightMatrix[feature,:] = weightMatrix[feature,:] - ((alpha/m)*summation)\n",
    "        \n",
    "        \n",
    "        cost.append(lossFunction(dataMatrix, weightMatrix , trainLabels))   #calculate loss with updated weights\n",
    "      \n",
    "        \n",
    "    return weightMatrix , cost\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Call gradient Decent\n",
    "no_epochs = 3000\n",
    "alpha = 0.01\n",
    "weights , cost  =  gradientscrochastic(trainDataMatrix, initialWeightMatrix, newTrainLabels ,alpha , no_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLoss(cost , no_epochs ): \n",
    "    plt.xticks(range(1,no_epochs))\n",
    "    plt.plot(cost)\n",
    "    plt.xlabel(\"No of iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotLoss(cost, no_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict labels\n",
    "def predictLabels(dataMatrix, weightMatrix):  \n",
    "\n",
    "    probablities = getProbablities(dataMatrix,weightMatrix )\n",
    "    \n",
    "\n",
    "    predictedLabels =  np.zeros((probablities.shape[0],1))\n",
    "    \n",
    "    for k in range(probablities.shape[0]):\n",
    "        \n",
    "        predictedLabels[k] = np.argmax(probablities[k,:])\n",
    "        \n",
    "    return predictedLabels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    " #predict labels for test data\n",
    "predictedLableTest =  predictLabels(testDataMatrix, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns precision\n",
    "def getPrecision(TP, FP):  \n",
    "    return TP/(TP+FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns recall\n",
    "def getRecall(TP,FN):   \n",
    "    return TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    " # returns accuracy\n",
    "def getAccuracy(TP,  total):  \n",
    "    return TP/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evalution\n",
    "def perf_measure(y_actual, y_pred):\n",
    "    TP_Neutral = 0\n",
    "    FP_Neutral = 0\n",
    "    TN_Neutral = 0\n",
    "    FN_Neutral = 0\n",
    "    \n",
    "    TP_Positive = 0\n",
    "    FP_Positive = 0\n",
    "    TN_Positive = 0\n",
    "    FN_Positive = 0\n",
    "    \n",
    "    TP_Negative = 0\n",
    "    FP_Negative = 0\n",
    "    TN_Negative = 0\n",
    "    FN_Negative = 0\n",
    "    \n",
    "\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_actual[i]==y_pred[i]==0:\n",
    "            TP_Neutral  += 1\n",
    "        if y_actual[i]==y_pred[i]==1:\n",
    "            TP_Positive  += 1\n",
    "        if y_actual[i]==y_pred[i]==2:\n",
    "            TP_Negative += 1\n",
    "        \n",
    "        if  y_actual[i]==0 and y_pred[i]!=0:\n",
    "            FN_Neutral += 1\n",
    "        if y_actual[i] ==1 and y_pred[i]!=1:\n",
    "            FN_Positive += 1\n",
    "        if y_actual[i]==2 and y_pred[i]!=2:\n",
    "            FN_Negative += 1\n",
    "        \n",
    "        if  y_pred[i]==0 and y_actual[i]!=y_pred[i]:\n",
    "            FP_Neutral += 1\n",
    "        if  y_pred[i]==1 and y_actual[i]!=y_pred[i]:\n",
    "            FP_Positive += 1\n",
    "        if  y_pred[i]==2 and y_actual[i]!=y_pred[i]:\n",
    "            FP_Negative += 1\n",
    "     \n",
    "    precisionNeutral = getPrecision(TP_Neutral,FP_Neutral)\n",
    "    precisionPositive = getPrecision(TP_Positive,FP_Positive)\n",
    "    precisionNegative = getPrecision(TP_Negative,FP_Negative)\n",
    "        \n",
    "    recallNeutral = getRecall(TP_Neutral,FN_Neutral)\n",
    "    recallPositive = getRecall(TP_Positive,FN_Positive)\n",
    "    recallNegative =   getRecall(TP_Negative,FN_Negative)\n",
    "        \n",
    "    accuray =  getAccuracy((TP_Neutral+TP_Positive+TP_Negative), len(y_pred))\n",
    "        \n",
    "    print(f\"Precision of Neutral:{precisionNeutral}\")\n",
    "    print(f\"Precision of Positive:{precisionPositive}\")\n",
    "    print(f\"Precision of Negative:{precisionNegative}\")\n",
    "        \n",
    "    print(f\"Recall of Neutral:{recallNeutral}\")\n",
    "    print(f\"Recall of Positive:{recallPositive}\")\n",
    "    print(f\"Recall of Negative:{recallNegative}\")\n",
    "        \n",
    "    print(f\"Overall Accuracy:{accuray}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Neutral:0.6391554702495201\n",
      "Precision of Positive:0.8009708737864077\n",
      "Precision of Negative:0.6997929606625258\n",
      "Recall of Neutral:0.7055084745762712\n",
      "Recall of Positive:0.6991525423728814\n",
      "Recall of Negative:0.7161016949152542\n",
      "Overall Accuracy:0.7069209039548022\n"
     ]
    }
   ],
   "source": [
    " # prints evaluation report\n",
    "testLabels = np.array(testLabels, dtype = np.float)\n",
    "perf_measure(testLabels,predictedLableTest)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
